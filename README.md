# progression-disparities

For all python files, use `-h` flag for details on command-line arguments. 

## Install dependencies 

All code was tested using Python 3.9.18.

`conda env create -f progression_project.yml --name [environment_name]` (about 10 minutes)

`conda activate [environment_name]`

## Generate synthetic datasets

`python3 generate_data.py`

Saves synthetic datasets to a sub-directory within __generated_data/__. With no arguments, defaults to saving one datset in __generated_data/test_data/__. 

## Fit stan model on data

### Option 1: Fit model on a single dataset
 
`python3 fit_full_model.py` OR `python3 fit_ablated_model.py --stan_model [ablated_stan_model_name]`

Fits a stan model (stored in __stan_models/__) on a synthetic dataset and stores output in __stan_output/__. `fit_full_model.py` fits __full_model__, the full model from our paper. `fit_ablated_model.py` fits an ablated version of the full model; use a --stan_model argument of the form "__no_disparity[i]__" to fit the model that fails to account for disparity i.

### Option 2: Fit model on multiple datasets in parallel

`python3 parallelize_across_jobs.py --stan_model [stan_model_name] --num_jobs [num_jobs]`

Fits a stan model (__stan_models/[stan_model_name]__) on a specified number of synthetic datasets and stores output in __stan_output/__. Each model fit is submitted as a separate Slurm job. With no arguments, defaults to fitting __full_model__ on one dataset (stan_model_name='full_model', num_jobs=1). The script records dataset and stan output file paths for each run in the __file_paths__ directory. 

## Visualize stan output

Open `param_recovery_plots.ipynb` and `z_recovery_plots.ipynb` to visualize stan outputs. These notebooks read from a `file_paths.csv` file; this file is generated by the `parallelize_across_jobs.py` script. 

##
Email <esc99@cornell.edu> if you have any questions or issues!
